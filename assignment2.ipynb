{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "OnlineActivity='online_shoppers_intention.csv'\n",
    "activity = pd.read_csv(OnlineActivity)\n",
    "df=activity.copy()\n",
    "print df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print df.shape\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data exploration\n",
    "#The density graph of the Administrative column depicts the people interested in visiting the page\n",
    "df['Administrative'].plot(kind='density', xlim=(0,27))\n",
    "plt.title('Online Shopper\\'s Intention - Administrative Page visits')\n",
    "plt.xlabel('Administrative page visits')\n",
    "plt.show()\n",
    "\n",
    "#The density graph of the Informtional column depicts the people interest in visiting the page\n",
    "informdf=df.loc[lambda df: df['Informational']>0]\n",
    "informdf['Informational'].plot(kind='density', xlim=(0,24))\n",
    "plt.title('Online Shopper\\'s Intention - Informational Page visits')\n",
    "plt.xlabel('Informational page visits')\n",
    "plt.show()\n",
    "\n",
    "#The density graph of the Product Related column depicts the people interest in visiting the page\n",
    "df['ProductRelated'].plot(kind='density', xlim=(0,705))\n",
    "plt.title('Online Shopper\\'s Intention - Product related Page visits')\n",
    "plt.xlabel('Product related page visits')\n",
    "plt.show()\n",
    "\n",
    "#The density graph of the Bounce Rate column depicts the people interest in visiting the page\n",
    "df['BounceRates'].plot(kind='density', xlim=(0,0.2))\n",
    "plt.title('Online Shopper\\'s Intention - Bounce Rate distribution across sessions')\n",
    "plt.xlabel('Bounce rate')\n",
    "plt.show()\n",
    "\n",
    "#The density graph of the Exit Rate column depicts the people interest in visiting the page\n",
    "df['ExitRates'].plot(kind='density', xlim=(0,0.2))\n",
    "plt.title('Online Shopper\\'s Intention - Exit Rate distribution across sessions')\n",
    "plt.xlabel('Exit rate')\n",
    "plt.show()\n",
    "\n",
    "#We check the number of sessions per month to illustrate the popularity of website in these months\n",
    "df['Month'].value_counts().plot(kind='pie',autopct='%.2f')  \n",
    "plt.show()\n",
    "\n",
    "#Piechart to depict Number of sessions based on the special day.\n",
    "df['SpecialDay'].value_counts().plot(kind='pie')  \n",
    "plt.show()\n",
    "\n",
    "#Plot to prove the hypotheis that value of special day depends on the month of the year.\n",
    "df.boxplot(column='SpecialDay',by='Month')\n",
    "plt.show()\n",
    "\n",
    "#plot to depict Returning visitors should have a higher number of account related page visits.\n",
    "df.boxplot(column='Administrative',by='VisitorType')\n",
    "plt.show()\n",
    "\n",
    "#People who visit a greater number of product related pages are less likely to exit the session.\n",
    "df.plot(kind='scatter',x=7,y=4)\n",
    "plt.show()\n",
    "\n",
    "#People who visit a greater number of Product related pages have less bounce rates\n",
    "df.plot(kind='scatter',x=6,y=4)\n",
    "plt.show()\n",
    "\n",
    "#plot to determine If the duration of a product related page increases, the number of page visits on product related page should also increase.\n",
    "df.plot(kind='scatter',x=5,y=4)\n",
    "plt.show()\n",
    "\n",
    "#Plot to determine whether the bounce rate can be used to determine the exit rate\n",
    "df.plot(kind='scatter',x=6,y=7)\n",
    "plt.show()df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rev = df.loc[lambda df: df['Revenue'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', \n",
    "      'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay']\n",
    "df_data = df[cols]\n",
    "df_target=df['Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original data using 50-50 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data,df_target,test_size=0.50,random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original data using 60-40 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data,df_target,test_size=0.40,random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original data using 80-20 split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data,df_target,test_size=0.20,random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing imbalanced-learn package to perform oversampling using SMOTE\n",
    "import sys\n",
    "!{sys.executable} -m pip install imbalanced-learn\n",
    "\n",
    "#Importing SMOTE from imblearn\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling script using SMOTE\n",
    "print(\"Before OverSampling, counts of label 'True': {}\".format(sum(df_target==True)))\n",
    "print(\"Before OverSampling, counts of label 'False': {} \\n\".format(sum(df_target==False)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "df_data_over, df_target_over = sm.fit_sample(df_data, df_target.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(df_data_over.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(df_target_over.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'True': {}\".format(sum(df_target_over==True)))\n",
    "print(\"After OverSampling, counts of label 'False': {}\".format(sum(df_target_over==False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 50-50\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_over, df_target_over, test_size=0.50, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 60-40\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_over, df_target_over, test_size=0.40, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 80-20\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_over, df_target_over, test_size=0.20, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Performing Hill-climbing feature selection\n",
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 1)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 3)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 5)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 7)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 9)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 10)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "new_Ind = []\n",
    "cur_MaxScore = 0.0\n",
    "col_num = 10\n",
    "col_Ind_Random = shuffle(range(0,col_num), random_state = 4)\n",
    "for cur_f in range(0, col_num):\n",
    "    new_Ind.append(col_Ind_Random[cur_f])\n",
    "    newData = df_data_over[:, new_Ind]\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(newData, df_target_over, test_size=0.4, random_state=0)\n",
    "    clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "    fit = clf.fit(X_train, y_train)\n",
    "    cur_Score = clf.score(X_test, y_test)\n",
    "    if cur_Score < cur_MaxScore:\n",
    "        new_Ind.remove(col_Ind_Random[cur_f])\n",
    "    else:\n",
    "        cur_MaxScore = cur_Score\n",
    "        print \"Score with \" + str(len(new_Ind)) + \" selected features: \" + str(cur_Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print new_Ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using only the selected features\n",
    "new_cols=['ProductRelated', 'PageValues', 'SpecialDay']\n",
    "df_hill_data = df[new_cols]\n",
    "df_hill_target=df['Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Smote on features selected from Hill-climbing\n",
    "print(\"Before OverSampling, counts of label 'True': {}\".format(sum(df_hill_target==True)))\n",
    "print(\"Before OverSampling, counts of label 'False': {} \\n\".format(sum(df_hill_target==False)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "df_hill_data_over, df_hill_target_over = sm.fit_sample(df_hill_data, df_hill_target.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(df_hill_data_over.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(df_hill_target_over.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'True': {}\".format(sum(df_hill_target_over==True)))\n",
    "print(\"After OverSampling, counts of label 'False': {}\".format(sum(df_hill_target_over==False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 50-50 without tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.50, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 60-40 without tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.40, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 50-50 without tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.20, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 50-50 with tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.50, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5, weights='distance')\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 60-40 with tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.40, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5, weights='distance')\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 80-20 with tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.20, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5, weights='distance')\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 60-40 with tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.40, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5, weights='distance', p=2)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#k-neighbor after smote 60-40 with tune with selected features\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_hill_data_over, df_hill_target_over, test_size=0.40, random_state=4)\n",
    "print(\"Number transactions X_train dataset: \", X_train.shape)\n",
    "print(\"Number transactions y_train dataset: \", y_train.shape)\n",
    "print(\"Number transactions X_test dataset: \", X_test.shape)\n",
    "print(\"Number transactions y_test dataset: \", y_test.shape)\n",
    "from sklearn.neighbors import KNeighborsClassifier  \n",
    "clf = KNeighborsClassifier(5, weights='distance', p=1)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre=fit.predict(X_test)\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test, y_pre)\n",
    "print cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Factorizing categorical columns to numerical using label encoder\n",
    "#Factorizing Month data\n",
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(df['Month'])\n",
    "list(le.classes_)\n",
    "df['Month']=le.transform(df['Month'])\n",
    "#Factorizing VisitorType data\n",
    "le.fit(df['VisitorType'])\n",
    "list(le.classes_)\n",
    "df['VisitorType']=le.transform(df['VisitorType'])\n",
    "\n",
    "#Starting decision tree\n",
    "cols=['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration', 'ProductRelated', 'ProductRelated_Duration', \n",
    "      'BounceRates', 'ExitRates', 'PageValues', 'SpecialDay', 'Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend']\n",
    "df_data_tree = df[cols]\n",
    "df_target_tree = df['Revenue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OverSampling script using SMOTE for Decision tree\n",
    "print(\"Before OverSampling, counts of label 'True': {}\".format(sum(df_target_tree == True)))\n",
    "print(\"Before OverSampling, counts of label 'False': {} \\n\".format(sum(df_target_tree == False)))\n",
    "\n",
    "sm = SMOTE(random_state=2)\n",
    "df_data_tree_over, df_target_tree_over = sm.fit_sample(df_data_tree, df_target_tree.ravel())\n",
    "\n",
    "print('After OverSampling, the shape of train_X: {}'.format(df_data_tree_over.shape))\n",
    "print('After OverSampling, the shape of train_y: {} \\n'.format(df_target_tree_over.shape))\n",
    "\n",
    "print(\"After OverSampling, counts of label 'True': {}\".format(sum(df_target_tree_over==True)))\n",
    "print(\"After OverSampling, counts of label 'False': {}\".format(sum(df_target_tree_over==False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree with oversampled data of all the features and 50-50 split with max-depth=3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_tree_over, df_target_tree_over, test_size=0.50, random_state=0)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth = 3)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "y_pre\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree with oversampled data of all the features and 60-40 split with max-depth=3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_tree_over, df_target_tree_over, test_size=0.40, random_state=0)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth = 3)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "y_pre\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree with oversampled data of all the features and 80-20 split with max-depth=3\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_tree_over, df_target_tree_over, test_size=0.20, random_state=0)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth = 3)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "y_pre\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Decision tree with oversampled data of all the features and 60-40 split with max-depth=4\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data_tree_over, df_target_tree_over, test_size=0.40, random_state=0)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf = DecisionTreeClassifier(max_depth = 4)\n",
    "fit = clf.fit(X_train, y_train)\n",
    "y_pre = fit.predict(X_test)\n",
    "y_pre\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pre)\n",
    "print cm\n",
    "from sklearn.metrics import classification_report\n",
    "print classification_report(y_test,y_pre)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "with open('osi_tree.dot', 'w') as f:\n",
    "    f = tree.export_graphviz(clf, out_file=f, feature_names=cols, class_names=['False', 'True'], filled=True, rounded=True, special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
